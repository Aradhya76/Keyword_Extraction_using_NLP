{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Reviews Keyword Extraction \u2014 Negative Reviews\n",
        "\n",
        "This Colab notebook demonstrates how to generate synthetic customer reviews, label negative reviews, and extract keywords from negative reviews using TF-IDF and simple statistical scoring. Everything in this repo is synthetic and created for demonstration only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install and import dependencies\n",
        "Run the cell below in Colab to install any missing packages and download NLTK data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Install required packages (uncomment when running in fresh Colab)\n",
        "!pip install -q nltk scikit-learn pandas\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print('Dependencies ready')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Create synthetic dataset\n",
        "We'll generate a small synthetic dataset of service reviews with some negative and positive examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "negative_templates = [\n",
        "    'Very disappointed with the service. {}',\n",
        "    'Poor experience: {}',\n",
        "    'Terrible support. {}',\n",
        "    'I waited too long and {}',\n",
        "    'The {} was unacceptable and frustrating.'\n",
        "]\n",
        "positive_templates = [\n",
        "    'Great service, {}',\n",
        "    'Very happy with the quick response: {}',\n",
        "    'Excellent support. {}',\n",
        "    'Loved the {} and the staff were helpful.'\n",
        "]\n",
        "negative_phrases = [\n",
        "    'agent was rude',\n",
        "    'took ages to resolve',\n",
        "    'problem still not fixed',\n",
        "    'charged me extra',\n",
        "    'could not reach anyone',\n",
        "    'kept transferring my call',\n",
        "    'billing issue not resolved',\n",
        "    'promised callback never came',\n",
        "    'website kept crashing',\n",
        "    'service outage for hours'\n",
        "]\n",
        "positive_phrases = [\n",
        "    'friendly staff',\n",
        "    'quick resolution',\n",
        "    'helpful support',\n",
        "    'refund processed smoothly',\n",
        "    'very satisfied'\n",
        "]\n",
        "rows = []\n",
        "for i in range(300):\n",
        "    if random.random() < 0.45:\n",
        "        t = random.choice(negative_templates)\n",
        "        phrase = random.choice(negative_phrases)\n",
        "        review = t.format(phrase)\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        t = random.choice(positive_templates)\n",
        "        phrase = random.choice(positive_phrases)\n",
        "        review = t.format(phrase)\n",
        "        sentiment = 'positive'\n",
        "    rows.append({'review_id': i+1, 'review': review, 'sentiment': sentiment})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Simple EDA\n",
        "Show counts and sample negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Total reviews:', len(df))\n",
        "print(df['sentiment'].value_counts())\n",
        "df[df['sentiment']=='negative'].sample(5, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Keyword extraction for negative reviews using TF-IDF\n",
        "We'll extract keywords by computing TF-IDF on the negative reviews corpus and selecting the top terms by average TF-IDF score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "neg_df = df[df['sentiment']=='negative'].copy()\n",
        "corpus = neg_df['review'].tolist()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_words, max_df=0.85, min_df=1)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# average tf-idf score per term across negative corpus\n",
        "avg_tfidf = np.asarray(X.mean(axis=0)).ravel()\n",
        "top_n = 30\n",
        "top_idx = np.argsort(avg_tfidf)[::-1][:top_n]\n",
        "top_terms = [(terms[i], round(avg_tfidf[i],4)) for i in top_idx]\n",
        "import pandas as pd\n",
        "pd.DataFrame(top_terms, columns=['term','avg_tfidf']).head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Extract keywords per review (top terms per review)\n",
        "We can also extract top-k tf-idf terms for each negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def top_keywords_for_doc(doc_idx, k=5):\n",
        "    row = X[doc_idx].toarray().ravel()\n",
        "    idx = row.argsort()[::-1][:k]\n",
        "    return [(terms[i], round(row[i],4)) for i in idx if row[i]>0]\n",
        "\n",
        "neg_df = neg_df.reset_index(drop=True)\n",
        "neg_df['top_keywords'] = neg_df.index.map(lambda i: top_keywords_for_doc(i, k=5))\n",
        "neg_df[['review','top_keywords']].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Simple phrase scoring (frequency + TF-IDF) for multi-word phrases\n",
        "We'll score candidate phrases (from n-grams) by combining document frequency and average TF-IDF to produce a ranked list of *keywords/phrases* relevant to negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from collections import Counter\n",
        "\n",
        "# get candidate phrases and their document frequency\n",
        "df_counts = Counter()\n",
        "tfidf_scores = {}\n",
        "for i, term in enumerate(terms):\n",
        "    df_counts[term] = (X[:, i].toarray().ravel() > 0).sum()\n",
        "    tfidf_scores[term] = avg_tfidf[i]\n",
        "\n",
        "candidates = []\n",
        "for term in terms:\n",
        "    # score = df * avg_tfidf (simple)\n",
        "    score = df_counts[term] * tfidf_scores[term]\n",
        "    candidates.append((term, df_counts[term], round(tfidf_scores[term],5), round(score,5)))\n",
        "\n",
        "cand_df = pd.DataFrame(candidates, columns=['phrase','doc_freq','avg_tfidf','score'])\n",
        "cand_df = cand_df.sort_values('score', ascending=False).head(40)\n",
        "cand_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Save results and export\n",
        "Save negative keywords to a CSV for inspection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "out_csv = '/content/negative_keywords.csv'\n",
        "cand_df.to_csv(out_csv, index=False)\n",
        "print('Saved candidate keywords to', out_csv)\n",
        "display(cand_df.head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes and next steps\n",
        "- This notebook uses synthetic data for demonstration (see repository README).\n",
        "- For production: consider using YAKE, RAKE, or Multi-word phrase extraction with more advanced preprocessing, lemmatization, and domain-specific stopwords.\n",
        "- You can extend this to cluster negative reviews and extract cluster-specific keywords."
      ]
    }
  ]
}