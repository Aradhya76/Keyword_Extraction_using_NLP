{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8uyC1QF19w"
      },
      "source": [
        "# Install required packages (uncomment when running in fresh Colab)\n",
        "!pip install -q nltk scikit-learn pandas\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print('Dependencies ready')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "LJ8uyC1QF19w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djfC0AHPF19x"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "negative_templates = [\n",
        "    'Very disappointed with the service. {}',\n",
        "    'Poor experience: {}',\n",
        "    'Terrible support. {}',\n",
        "    'I waited too long and {}',\n",
        "    'The {} was unacceptable and frustrating.'\n",
        "]\n",
        "positive_templates = [\n",
        "    'Great service, {}',\n",
        "    'Very happy with the quick response: {}',\n",
        "    'Excellent support. {}',\n",
        "    'Loved the {} and the staff were helpful.'\n",
        "]\n",
        "negative_phrases = [\n",
        "    'agent was rude',\n",
        "    'took ages to resolve',\n",
        "    'problem still not fixed',\n",
        "    'charged me extra',\n",
        "    'could not reach anyone',\n",
        "    'kept transferring my call',\n",
        "    'billing issue not resolved',\n",
        "    'promised callback never came',\n",
        "    'website kept crashing',\n",
        "    'service outage for hours'\n",
        "]\n",
        "positive_phrases = [\n",
        "    'friendly staff',\n",
        "    'quick resolution',\n",
        "    'helpful support',\n",
        "    'refund processed smoothly',\n",
        "    'very satisfied'\n",
        "]\n",
        "rows = []\n",
        "for i in range(300):\n",
        "    if random.random() < 0.45:\n",
        "        t = random.choice(negative_templates)\n",
        "        phrase = random.choice(negative_phrases)\n",
        "        review = t.format(phrase)\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        t = random.choice(positive_templates)\n",
        "        phrase = random.choice(positive_phrases)\n",
        "        review = t.format(phrase)\n",
        "        sentiment = 'positive'\n",
        "    rows.append({'review_id': i+1, 'review': review, 'sentiment': sentiment})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "djfC0AHPF19x"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcxJ-LeCF19x"
      },
      "source": [
        "print('Total reviews:', len(df))\n",
        "print(df['sentiment'].value_counts())\n",
        "df[df['sentiment']=='negative'].sample(5, random_state=1)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "XcxJ-LeCF19x"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4WYi9ahF19x"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "neg_df = df[df['sentiment']=='negative'].copy()\n",
        "corpus = neg_df['review'].tolist()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_words, max_df=0.85, min_df=1)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# average tf-idf score per term across negative corpus\n",
        "avg_tfidf = np.asarray(X.mean(axis=0)).ravel()\n",
        "top_n = 30\n",
        "top_idx = np.argsort(avg_tfidf)[::-1][:top_n]\n",
        "top_terms = [(terms[i], round(avg_tfidf[i],4)) for i in top_idx]\n",
        "import pandas as pd\n",
        "pd.DataFrame(top_terms, columns=['term','avg_tfidf']).head(30)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "z4WYi9ahF19x"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VnGwO3HF19y"
      },
      "source": [
        "def top_keywords_for_doc(doc_idx, k=5):\n",
        "    row = X[doc_idx].toarray().ravel()\n",
        "    idx = row.argsort()[::-1][:k]\n",
        "    return [(terms[i], round(row[i],4)) for i in idx if row[i]>0]\n",
        "\n",
        "neg_df = neg_df.reset_index(drop=True)\n",
        "neg_df['top_keywords'] = neg_df.index.map(lambda i: top_keywords_for_doc(i, k=5))\n",
        "neg_df[['review','top_keywords']].head(10)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2VnGwO3HF19y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAIaVgemF19y"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# get candidate phrases and their document frequency\n",
        "df_counts = Counter()\n",
        "tfidf_scores = {}\n",
        "for i, term in enumerate(terms):\n",
        "    df_counts[term] = (X[:, i].toarray().ravel() > 0).sum()\n",
        "    tfidf_scores[term] = avg_tfidf[i]\n",
        "\n",
        "candidates = []\n",
        "for term in terms:\n",
        "    # score = df * avg_tfidf (simple)\n",
        "    score = df_counts[term] * tfidf_scores[term]\n",
        "    candidates.append((term, df_counts[term], round(tfidf_scores[term],5), round(score,5)))\n",
        "\n",
        "cand_df = pd.DataFrame(candidates, columns=['phrase','doc_freq','avg_tfidf','score'])\n",
        "cand_df = cand_df.sort_values('score', ascending=False).head(40)\n",
        "cand_df"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "OAIaVgemF19y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0dg7LVqF19y"
      },
      "source": [
        
      ],
      "id": "w0dg7LVqF19y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sUdFXSEF19y"
      },
      "source": [
        "out_csv = '/content/negative_keywords.csv'\n",
        "cand_df.to_csv(out_csv, index=False)\n",
        "print('Saved candidate keywords to', out_csv)\n",
        "display(cand_df.head(20))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4sUdFXSEF19y"
    }
  ]
}
